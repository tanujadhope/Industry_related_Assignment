{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JCl6YLOde7XYWGZF5ZxzQ32ua0c4WZsC","timestamp":1685358710317}],"authorship_tag":"ABX9TyO4VgbuI0sZcY14i1CddZsA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#### Q3 Train a Pure CNN with less than 10000 trainable parameters using the MNISTDataset having minimum validation accuracy of 99.40%\n","Note -\n","1. Code comments should be given for proper code understanding.\n","2. Implement in both PyTorch and Tensorflow respectively"],"metadata":{"id":"6qWEt7jZ36qr"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.datasets import mnist\n","from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n","from keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical"],"metadata":{"id":"Bt502BYjZ0Ub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","(x_train,y_train),(x_test,y_test)=mnist.load_data()"],"metadata":{"id":"Fzh04L10aMAv","executionInfo":{"status":"ok","timestamp":1685368601911,"user_tz":-330,"elapsed":1333,"user":{"displayName":"Tanuja Dhope","userId":"02491285439870477769"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Load MNIST dataset\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Reshape and normalize input data\n","x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n","x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n","\n","# One-hot encode the target labels\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# Define the CNN architecture\n","model = Sequential([\n","    Conv2D(8, (3, 3), activation='tanh', input_shape=(28, 28, 1)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(16, (3, 3), activation='tanh'),\n","    MaxPooling2D((2, 2)),\n","#    Dropout(0.5),\n","    Flatten(),\n","    Dense(20, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","# Print the model summary\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XnCwyXj-bFAD","executionInfo":{"status":"ok","timestamp":1685368711523,"user_tz":-330,"elapsed":1706,"user":{"displayName":"Tanuja Dhope","userId":"02491285439870477769"}},"outputId":"ccbe730e-1465-47c2-be16-1b079993cabd"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_2 (Conv2D)           (None, 26, 26, 8)         80        \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 13, 13, 8)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 11, 11, 16)        1168      \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 5, 5, 16)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_1 (Flatten)         (None, 400)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 20)                8020      \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                210       \n","                                                                 \n","=================================================================\n","Total params: 9,478\n","Trainable params: 9,478\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_test, y_test))\n","\n","# Evaluate the model on the test set\n","_, accuracy = model.evaluate(x_test, y_test)\n","print(\"Test Accuracy:\", accuracy*100)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-58n2bixiQgN","executionInfo":{"status":"ok","timestamp":1685368982221,"user_tz":-330,"elapsed":37142,"user":{"displayName":"Tanuja Dhope","userId":"02491285439870477769"}},"outputId":"2c6d3f8d-7128-4760-c22c-252d6ce9ff85"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","1875/1875 [==============================] - 12s 4ms/step - loss: 0.2926 - accuracy: 0.9139 - val_loss: 0.1056 - val_accuracy: 0.9668\n","Epoch 2/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0953 - accuracy: 0.9711 - val_loss: 0.0651 - val_accuracy: 0.9790\n","Epoch 3/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0714 - accuracy: 0.9786 - val_loss: 0.0550 - val_accuracy: 0.9826\n","Epoch 4/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0613 - accuracy: 0.9813 - val_loss: 0.0519 - val_accuracy: 0.9829\n","Epoch 5/25\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.0474 - val_accuracy: 0.9842\n","Epoch 6/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.0487 - val_accuracy: 0.9845\n","Epoch 7/25\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0414 - accuracy: 0.9871 - val_loss: 0.0410 - val_accuracy: 0.9865\n","Epoch 8/25\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 0.0424 - val_accuracy: 0.9850\n","Epoch 9/25\n","1875/1875 [==============================] - 11s 6ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0396 - val_accuracy: 0.9874\n","Epoch 10/25\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.0397 - val_accuracy: 0.9880\n","Epoch 11/25\n","1875/1875 [==============================] - 12s 6ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.0450 - val_accuracy: 0.9855\n","Epoch 12/25\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.0410 - val_accuracy: 0.9848\n","Epoch 13/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0477 - val_accuracy: 0.9854\n","Epoch 14/25\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0463 - val_accuracy: 0.9875\n","Epoch 15/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0506 - val_accuracy: 0.9850\n","Epoch 16/25\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0499 - val_accuracy: 0.9866\n","Epoch 17/25\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.0536 - val_accuracy: 0.9846\n","Epoch 18/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0534 - val_accuracy: 0.9851\n","Epoch 19/25\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.0479 - val_accuracy: 0.9855\n","Epoch 20/25\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0482 - val_accuracy: 0.9876\n","Epoch 21/25\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0557 - val_accuracy: 0.9855\n","Epoch 22/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0553 - val_accuracy: 0.9860\n","Epoch 23/25\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0534 - val_accuracy: 0.9856\n","Epoch 24/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0544 - val_accuracy: 0.9865\n","Epoch 25/25\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0592 - val_accuracy: 0.9863\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0592 - accuracy: 0.9863\n","Test Accuracy: 98.6299991607666\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import ToTensor\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","# Set device check for availbility of GPU \n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load MNIST dataset\n","train_dataset = MNIST(root=\"./data\", train=True, download=True, transform=ToTensor())\n","test_dataset = MNIST(root=\"./data\", train=False, download=True, transform=ToTensor())\n","\n","# Define indices for train-validation split\n","num_samples = len(train_dataset)\n","indices = list(range(num_samples))\n","split = int(0.8 * num_samples)  # 80% train, 20% validation\n","train_indices, val_indices = indices[:split], indices[split:]\n","\n","# Create data loaders\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)\n","val_loader = DataLoader(train_dataset, batch_size=32, sampler=val_sampler)\n","test_loader = DataLoader(test_dataset, batch_size=32)\n","\n","# Define the CNN architecture\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=1)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 20)\n","        self.relu3 = nn.ReLU()\n","        self.fc2 = nn.Linear(20, 10)\n","\n","    def forward(self, x):\n","        x = self.pool1(self.relu1(self.conv1(x)))\n","        x = self.pool2(self.relu2(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = self.dropout(x)\n","        x = self.relu3(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Create the model instance\n","model = Net().to(device)\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters())\n","\n","# Training loop\n","num_epochs = 25\n","best_val_acc = 0.0\n","\n","for epoch in range(num_epochs):\n","    # Training\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        train_correct += (predicted == labels).sum().item()\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    train_acc = 100.0 * train_correct / len(train_indices)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    val_correct = 0\n","\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","    val_acc = 100.0 * val_correct / len(val_indices)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n","          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n","\n","    # Save the model with the best validation accuracy\n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","        torch.save(model.state_dict(), \"best_model.pt\")\n","\n","# Load the best model weights\n","model.load_state_dict(torch.load(\"best_model.pt\"))\n","\n","# Evaluation on test set\n","model.eval()\n","test_correct = 0\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        test_correct += (predicted == labels).sum().item()\n","\n","test_acc = 100.0 * test_correct / len(test_dataset)\n","\n","print(f\"Test Accuracy: {test_acc:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFOplCj9zr1U","executionInfo":{"status":"ok","timestamp":1685369712621,"user_tz":-330,"elapsed":320301,"user":{"displayName":"Tanuja Dhope","userId":"02491285439870477769"}},"outputId":"dd713499-df61-48fc-d56a-1fde040699a9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 191307500.53it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 100946411.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 71129924.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 7290673.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Epoch 1/25: Train Loss: 782.2147, Train Acc: 83.28%, Val Loss: 47.2231, Val Acc: 96.32%\n","Epoch 2/25: Train Loss: 305.3259, Train Acc: 93.79%, Val Loss: 33.6214, Val Acc: 97.51%\n","Epoch 3/25: Train Loss: 252.0562, Train Acc: 94.85%, Val Loss: 28.8628, Val Acc: 97.85%\n","Epoch 4/25: Train Loss: 228.1653, Train Acc: 95.33%, Val Loss: 26.7154, Val Acc: 97.96%\n","Epoch 5/25: Train Loss: 206.9610, Train Acc: 95.70%, Val Loss: 25.8790, Val Acc: 97.97%\n","Epoch 6/25: Train Loss: 193.2620, Train Acc: 95.92%, Val Loss: 22.3346, Val Acc: 98.32%\n","Epoch 7/25: Train Loss: 178.4615, Train Acc: 96.33%, Val Loss: 22.6066, Val Acc: 98.30%\n","Epoch 8/25: Train Loss: 172.8802, Train Acc: 96.35%, Val Loss: 23.0035, Val Acc: 98.35%\n","Epoch 9/25: Train Loss: 165.2192, Train Acc: 96.43%, Val Loss: 20.7274, Val Acc: 98.40%\n","Epoch 10/25: Train Loss: 155.4549, Train Acc: 96.66%, Val Loss: 19.3646, Val Acc: 98.50%\n","Epoch 11/25: Train Loss: 153.7626, Train Acc: 96.77%, Val Loss: 18.7015, Val Acc: 98.61%\n","Epoch 12/25: Train Loss: 148.6929, Train Acc: 96.92%, Val Loss: 17.4591, Val Acc: 98.71%\n","Epoch 13/25: Train Loss: 142.1225, Train Acc: 97.09%, Val Loss: 18.6967, Val Acc: 98.72%\n","Epoch 14/25: Train Loss: 143.1564, Train Acc: 97.03%, Val Loss: 16.6322, Val Acc: 98.76%\n","Epoch 15/25: Train Loss: 135.4481, Train Acc: 97.17%, Val Loss: 16.7796, Val Acc: 98.79%\n","Epoch 16/25: Train Loss: 133.0635, Train Acc: 97.24%, Val Loss: 16.0625, Val Acc: 98.82%\n","Epoch 17/25: Train Loss: 127.9204, Train Acc: 97.31%, Val Loss: 15.6367, Val Acc: 98.95%\n","Epoch 18/25: Train Loss: 125.2967, Train Acc: 97.31%, Val Loss: 15.6491, Val Acc: 98.79%\n","Epoch 19/25: Train Loss: 122.4150, Train Acc: 97.44%, Val Loss: 15.4642, Val Acc: 98.88%\n","Epoch 20/25: Train Loss: 120.0314, Train Acc: 97.48%, Val Loss: 15.1220, Val Acc: 98.92%\n","Epoch 21/25: Train Loss: 118.1679, Train Acc: 97.48%, Val Loss: 15.0267, Val Acc: 98.87%\n","Epoch 22/25: Train Loss: 117.5146, Train Acc: 97.51%, Val Loss: 15.1466, Val Acc: 98.91%\n","Epoch 23/25: Train Loss: 117.1709, Train Acc: 97.44%, Val Loss: 14.7910, Val Acc: 98.98%\n","Epoch 24/25: Train Loss: 115.8728, Train Acc: 97.60%, Val Loss: 15.5909, Val Acc: 98.92%\n","Epoch 25/25: Train Loss: 107.5673, Train Acc: 97.71%, Val Loss: 14.3166, Val Acc: 98.87%\n","Test Accuracy: 98.99%\n"]}]}]}