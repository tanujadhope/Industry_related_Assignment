{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f8c18e",
   "metadata": {},
   "source": [
    "Q4. Take any text file and now your task is to Text Summarization without using\n",
    "hugging transformer library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78710da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import heapq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d120a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution Given: Total bandwidth = 33 MHz Channel bandwidth = 25 kHz Ã— 2 simplex channels = 50 kHz/duplex channel Total available channels = 33,000/50 = 660 channels (a) For N = 4, total number of channels available per cell = 660/4 â‰ˆ 165 channels. (b) For N = 7, four cells with three control channels and 92 voice channels, two cells with three control channels and 90 voice channels, and one cell with two control channels and 92 voice channels could be allocated. Example 3.1 If a total of 33 MHz of bandwidth is allocated to a particular FDD cellular telephone system which uses two 25 kHz simplex channels to provide full duplex voice and control channels, compute the number of channels available per cell if a system uses (a) four-cell reuse, (b) seven-cell reuse, and (c) 12-cell reuse.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize text \n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return sentences, words\n",
    "\n",
    "def calculate_sentence_scores(sentences, words):\n",
    "    # Calculate word frequency\n",
    "    word_freq = defaultdict(int)\n",
    "    for word in words:\n",
    "        word_freq[word] += 1\n",
    "\n",
    "    # Calculate sentence \n",
    "    sentence_scores = defaultdict(int)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            if word in word_freq:\n",
    "                sentence_scores[i] += word_freq[word]\n",
    "\n",
    "    return sentence_scores\n",
    "\n",
    "def generate_summary(text, num_sentences=3):\n",
    "    sentences, words = preprocess_text(text)\n",
    "    sentence_scores = calculate_sentence_scores(sentences, words)\n",
    "\n",
    "    # Select the top N sentences with highest scores\n",
    "    summary_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join([sentences[i] for i in summary_sentences])\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "file_path = \"Test.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "\n",
    "summary = generate_summary(text)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317073c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
